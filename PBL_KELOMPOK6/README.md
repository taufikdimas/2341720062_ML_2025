# LAPORAN ANALISIS PROJECT-BASED LEARNING (PBL)

## KLASIFIKASI KUALITAS SAYURAN MENGGUNAKAN MACHINE LEARNING

---

## 1. PENDAHULUAN

### 1.1 Latar Belakang

Kualitas sayuran merupakan faktor penting dalam industri pertanian dan distribusi pangan. Identifikasi kualitas sayuran secara manual memerlukan waktu dan tenaga yang cukup besar. Oleh karena itu, penggunaan teknologi machine learning dapat membantu mengotomatisasi proses klasifikasi kualitas sayuran.

Project-Based Learning (PBL) ini berfokus pada pengembangan sistem klasifikasi kualitas sayuran menggunakan dua pendekatan machine learning: **Artificial Neural Network (ANN)** dan **Support Vector Machine (SVM)**. Penelitian ini melakukan eksperimen dengan berbagai rasio pembagian data training dan testing untuk menemukan konfigurasi optimal.

### 1.2 Rumusan Masalah

1. Bagaimana performa model ANN dan SVM dalam mengklasifikasikan kualitas sayuran?
2. Bagaimana pengaruh rasio split data terhadap akurasi model?
3. Model mana yang lebih baik untuk klasifikasi kualitas sayuran?

---

## 2. TUJUAN PENELITIAN

1. Mengimplementasikan model ANN dan SVM untuk klasifikasi kualitas sayuran
2. Mengevaluasi performa model dengan berbagai rasio split data (10:90, 20:80, 30:70, 40:60, 50:50, 60:40, 70:30, 80:20, 90:10)
3. Membandingkan performa kedua model berdasarkan akurasi, precision, recall, dan f1-score
4. Menentukan konfigurasi optimal untuk deployment sistem

---

## 3. DATASET

### 3.1 Sumber Dataset

Dataset yang digunakan adalah **Vegetables Quality Dataset** dari Kaggle:

- **Link**: https://www.kaggle.com/datasets/mdatikurrahman3111/vegetables-quality-dataset-2

### 3.2 Karakteristik Dataset

- **Jenis Data**: Gambar sayuran
- **Kategori Kualitas**:
  - **Utuh** (Good Quality)
  - **Rusak** (Bad Quality)
- **Total Gambar**: 8.920 gambar
- **Distribusi**:
  - Utuh: ~4.460 gambar
  - Rusak: ~4.460 gambar

### 3.3 Preprocessing dan Feature Extraction

1. **Image Preprocessing**:

   - Resizing gambar
   - Normalisasi pixel values
   - Grayscale conversion

2. **Feature Extraction**:

   - **Local Binary Pattern (LBP)**: Ekstraksi tekstur lokal
   - **Histogram of Oriented Gradients (HOG)**: Ekstraksi fitur bentuk dan edge
   - **Color Histogram**: Distribusi warna
   - **Statistical Features**: Mean, standard deviation, dll.

3. **Data Splitting**:
   - Training Set: Untuk melatih model
   - Validation Set: Untuk tuning hyperparameter
   - Test Set: Untuk evaluasi final

---

## 4. METODOLOGI

### 4.1 Model Artificial Neural Network (ANN)

**Arsitektur Model**:

```
Input Layer: [Jumlah fitur hasil ekstraksi]
Hidden Layer 1: 128 neurons + ReLU + L2 Regularization + BatchNormalization + Dropout(0.4)
Hidden Layer 2: 64 neurons + ReLU + L2 Regularization + BatchNormalization + Dropout(0.3)
Hidden Layer 3: 32 neurons + ReLU + L2 Regularization + BatchNormalization + Dropout(0.2)
Output Layer: 2 neurons + Softmax
```

**Training Configuration**:

- **Optimizer**: Adam
- **Learning Rate**: 0.001 (dengan ReduceLROnPlateau)
- **Loss Function**: Sparse Categorical Crossentropy
- **Batch Size**: 32
- **Epochs**: 100 (dengan Early Stopping)
- **Regularization**: L2, Dropout, BatchNormalization

### 4.2 Model Support Vector Machine (SVM)

**Konfigurasi Model**:

- **Kernel**: RBF (Radial Basis Function)
- **Parameter C**: Optimized via Grid Search
- **Parameter Gamma**: Optimized via Grid Search
- **Feature Scaling**: StandardScaler

**Hyperparameter Tuning**:

- Grid Search untuk mencari kombinasi optimal C dan gamma
- Cross-validation untuk validasi

### 4.3 Metrik Evaluasi

1. **Accuracy**: Proporsi prediksi benar terhadap total prediksi
2. **Precision**: Proporsi prediksi positif yang benar
3. **Recall**: Proporsi data positif yang terdeteksi
4. **F1-Score**: Harmonic mean dari precision dan recall

---

## 5. HASIL PERCOBAAN

### 5.1 Hasil Model ANN dengan Berbagai Rasio Split Data

| Split Ratio (Train:Test) | Validation Accuracy | Test Accuracy | Precision (Avg) | Recall (Avg) | F1-Score (Avg) |
| ------------------------ | ------------------- | ------------- | --------------- | ------------ | -------------- |
| 10:90                    | 77.95%              | ~78.00%       | ~0.78           | ~0.78        | ~0.78          |
| 20:80                    | 82.74%              | 83.22%        | ~0.83           | ~0.83        | ~0.83          |
| 30:70                    | 86.37%              | 85.63%        | ~0.86           | ~0.86        | ~0.86          |
| 40:60                    | 86.49%              | 84.25%        | ~0.84           | ~0.84        | ~0.84          |
| 50:50                    | 85.65%              | 86.55%        | ~0.87           | ~0.87        | ~0.87          |
| 60:40                    | 89.00%              | 89.73%        | ~0.90           | ~0.90        | ~0.90          |
| 70:30                    | 91.41%              | 90.66%        | ~0.91           | ~0.91        | ~0.91          |
| 80:20                    | 89.90%              | 90.46%        | ~0.90           | ~0.90        | ~0.90          |
| 90:10                    | 90.79%              | 92.83%        | ~0.93           | ~0.93        | ~0.93          |

**Analisis ANN**:

- âœ… **Performa terbaik**: Split 90:10 dengan Test Accuracy 92.83%
- âœ… **Performa stabil**: Split 70:30 dan 60:40 menunjukkan keseimbangan baik
- âš ï¸ **Data training sedikit**: Split 10:90 dan 20:80 menunjukkan performa rendah

### 5.2 Hasil Model SVM dengan Berbagai Rasio Split Data

| Split Ratio (Train:Test) | Validation Accuracy | Test Accuracy | Precision (Avg) | Recall (Avg) | F1-Score (Avg) |
| ------------------------ | ------------------- | ------------- | --------------- | ------------ | -------------- |
| 10:90                    | ~75.00%             | ~76.00%       | ~0.76           | ~0.76        | ~0.76          |
| 20:80                    | ~80.00%             | ~81.00%       | ~0.81           | ~0.81        | ~0.81          |
| 30:70                    | 86.50%              | 86.71%        | ~0.87           | ~0.87        | ~0.87          |
| 40:60                    | 88.55%              | 87.73%        | ~0.88           | ~0.88        | ~0.88          |
| 50:50                    | 89.81%              | 87.83%        | ~0.88           | ~0.88        | ~0.88          |
| 60:40                    | 90.57%              | 91.25%        | ~0.91           | ~0.91        | ~0.91          |
| 70:30                    | 86.71%              | 86.71%        | ~0.87           | ~0.87        | ~0.87          |
| 80:20                    | 93.49%              | 91.36%        | ~0.91           | ~0.91        | ~0.91          |
| 90:10                    | 91.01%              | 92.15%        | ~0.92           | ~0.92        | ~0.92          |

**Analisis SVM**:

- âœ… **Performa terbaik**: Split 90:10 dengan Test Accuracy 92.15%
- âœ… **Konsistensi tinggi**: Split 80:20 menunjukkan validation accuracy tertinggi (93.49%)
- âœ… **Generalisasi baik**: Gap antara training dan test relatif kecil

---

## 6. ANALISIS PERBANDINGAN MODEL

### 6.1 Perbandingan Akurasi Test

| Split Ratio | ANN Test Accuracy | SVM Test Accuracy | Selisih | Unggul |
| ----------- | ----------------- | ----------------- | ------- | ------ |
| 10:90       | ~78.00%           | ~76.00%           | +2.00%  | ANN    |
| 20:80       | 83.22%            | ~81.00%           | +2.22%  | ANN    |
| 30:70       | 85.63%            | 86.71%            | -1.08%  | SVM    |
| 40:60       | 84.25%            | 87.73%            | -3.48%  | SVM    |
| 50:50       | 86.55%            | 87.83%            | -1.28%  | SVM    |
| 60:40       | 89.73%            | 91.25%            | -1.52%  | SVM    |
| 70:30       | 90.66%            | 86.71%            | +3.95%  | ANN    |
| 80:20       | 90.46%            | 91.36%            | -0.90%  | SVM    |
| 90:10       | **92.83%**        | **92.15%**        | +0.68%  | ANN    |

### 6.2 Insight Utama

#### ğŸ“Š Pengaruh Rasio Split Data

1. **Data Training Sedikit (10-30%)**:

   - Performa kedua model rendah
   - ANN sedikit lebih baik dengan data minimal
   - Kedua model mengalami underfitting

2. **Data Training Sedang (40-60%)**:

   - SVM menunjukkan performa lebih stabil
   - ANN mulai menunjukkan improvement signifikan
   - Trade-off antara learning dan generalization

3. **Data Training Banyak (70-90%)**:
   - ANN mencapai performa optimal
   - SVM tetap konsisten
   - Gap performa semakin kecil

#### ğŸ¯ Kelebihan dan Kekurangan

**Artificial Neural Network (ANN)**:

- âœ… **Kelebihan**:

  - Performa terbaik dengan data training banyak (90:10 â†’ 92.83%)
  - Mampu menangkap pola kompleks
  - Fleksibel dengan berbagai jenis fitur
  - Dapat dioptimalkan dengan regularization dan dropout

- âŒ **Kekurangan**:
  - Membutuhkan data training yang banyak
  - Training time lebih lama
  - Memerlukan tuning hyperparameter yang cermat
  - Risiko overfitting jika tidak diregularisasi dengan baik

**Support Vector Machine (SVM)**:

- âœ… **Kelebihan**:

  - Konsisten di berbagai rasio split
  - Performa baik dengan data sedang (60:40 â†’ 91.25%)
  - Training time relatif cepat
  - Generalisasi baik dengan gap kecil

- âŒ **Kekurangan**:
  - Performa menurun dengan data training sangat banyak
  - Kurang fleksibel dibanding deep learning
  - Sensitif terhadap pemilihan kernel dan hyperparameter

### 6.3 Visualisasi Performa

```
Grafik Perbandingan Akurasi Test
â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”
100% â”¤
 95% â”¤                                     â—â”€â”€ANN
 90% â”¤                         â—â”€â—â”€â—   â—â”€â—â”€â—
 85% â”¤               â—â”€â—â”€â—â”€â—â”€â—           â– â”€â”€SVM
 80% â”¤       â—â”€â—â”€â—                     â– â”€â– â”€â– 
 75% â”¤   â—â”€â—                     â– â”€â– â”€â– 
 70% â”¤ â—                   â– â”€â– â”€â– 
     â””â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€â”´â”€
     10 20 30 40 50 60 70 80 90 (Train %)
```

---

## 7. KESIMPULAN

### 7.1 Kesimpulan Utama

1. **Model Terbaik**:

   - **ANN dengan split 90:10** mencapai akurasi tertinggi (92.83%)
   - **SVM dengan split 90:10** juga sangat kompetitif (92.15%)

2. **Pengaruh Split Data**:

   - Rasio training yang lebih besar (70-90%) menghasilkan performa terbaik
   - Data training minimal (10-30%) tidak cukup untuk kedua model
   - Sweet spot untuk SVM: 60:40 hingga 90:10
   - Sweet spot untuk ANN: 70:30 hingga 90:10

3. **Perbandingan Model**:

   - ANN unggul dengan data training yang banyak
   - SVM lebih stabil dan konsisten di berbagai konfigurasi
   - Selisih performa maksimal hanya ~4% (favorabel untuk deployment)

4. **Trade-off**:
   - **Akurasi vs Training Time**: ANN lebih akurat tapi lebih lambat
   - **Data Requirements vs Performance**: ANN butuh lebih banyak data untuk optimal
   - **Kompleksitas vs Maintainability**: SVM lebih mudah di-maintain

---
